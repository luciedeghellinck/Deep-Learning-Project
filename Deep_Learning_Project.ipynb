{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl6tKMMrRS/8oCnTrVqiGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciedeghellinck/Deep-Learning-Project/blob/master/Deep_Learning_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n: number of input data \\\\\n",
        "m: number of features per input data \\\\\n",
        "X: feature vector"
      ],
      "metadata": {
        "id": "yw1o8Pyhgrtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Propensity calculations**"
      ],
      "metadata": {
        "id": "O2SKpLyo_zQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def propensityScore(dataset, feature_x): \n",
        "  \"\"\"\n",
        "  Calculates the propensity score e(x) = P(T=1|X=x) \n",
        "\n",
        "  Args: \n",
        "    dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "    feature_x: n dimensional float feature vector whose propensity must be \n",
        "      calculated  \n",
        "  Returns: \n",
        "    The float propensity relative to the given feature vector feature_x\n",
        "  \"\"\"\n",
        "  sum_true = 0\n",
        "  for person in dataset.data: \n",
        "    if person[0] == feature_x: \n",
        "      if person[1] == 1: \n",
        "        sum_true += 1\n",
        "  propensity = sum_true / dataset.size\n",
        "\n",
        "def propensityRegression(dataset): \n",
        "  \"\"\"\n",
        "  Evaluates a regression function for the propensity given the known \n",
        "  propensity scores\n",
        "\n",
        "  Args: \n",
        "    dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "  \n",
        "  Returns: \n",
        "    A function that takes an m dimensional feature vector as input and \n",
        "    estimates its propensity\n",
        "  \"\"\"\n",
        "\n",
        "def propensityEstimate(dataset, new_feature_x): \n",
        "  \"\"\"\n",
        "  Using the function obtained from propensityRegression, the estimate of \n",
        "  the propensity of a new feature vector is calculated.\n",
        "\n",
        "  Args: \n",
        "    dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "    new_feature_x: n dimensional float feature vector whose propensity \n",
        "    must be approximated.\n",
        "  Returns: \n",
        "    The estimated propensity score of the new input feature vector. \n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "Q6iL2ZJZ_cTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IPM calculation**"
      ],
      "metadata": {
        "id": "1vLPtjcCAD9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def IPM(dataset, representation_false, representation_true): \n",
        "  #Not sure about how this works... I don't know what is the set of \n",
        "  # functions G\n",
        "  \"\"\"\n",
        "  Calculates the IPM distance for two probability functions.\n",
        "\n",
        "  Args: \n",
        "    dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "    representation_false: \n",
        "    representation_true:\n",
        "  Returns: \n",
        "    The IPM distance evaluated on all \n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "5YkpDXWV_PMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight calculation**"
      ],
      "metadata": {
        "id": "vXQjcnf6ATAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weight(dataset, X, T):\n",
        "  \"\"\"\n",
        "  Calculates the weight for a given feature vector and a given treatment type.\n",
        "\n",
        "  Args: \n",
        "   dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "    X: m dimensional float feature vector\n",
        "    T: 0/1 treatment type.\n",
        "  Returns: \n",
        "    The float weight for the feature vector and the treatment type.\n",
        "  \"\"\"\n",
        "  propensity = propensityEstimate(dataset, X)\n",
        "  weight = (T * (1 - 2 * propensity) + propensity**2) / (propensity * (1 - propensity))\n",
        "  \n",
        "  return weight\n",
        "\n",
        "def pi(dataset, T)\n",
        "  \"\"\"\n",
        "  Calculates the percentage of a given treatment type for the dataset.\n",
        "\n",
        "  Args: \n",
        "    dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "    T: 0/1 treatment type.\n",
        "\n",
        "  Returns: \n",
        "    The float percentage of the treatment type.\n",
        "  \"\"\"\n",
        "  sum = 0\n",
        "  for treatment in dataset.data[1]: \n",
        "    if treatement == T: \n",
        "      sum += 1\n",
        "  pi = sum / dataset.size\n",
        "\n",
        "  return pi\n",
        "\n",
        "def adaptedWeight(dataset, X, T): \n",
        "  \"\"\"\n",
        "  Calculates the weight for a given feature vector and a given treatment type.\n",
        "\n",
        "  Args: \n",
        "   dataset: torch tensor where each row represents a person, the first \n",
        "      column represents the float feature vector, the second is the 0/1 \n",
        "      treatment type and the third is the float outcome.\n",
        "    X: m dimensional float feature vector\n",
        "    T: 0/1 treatment type.\n",
        "\n",
        "  Returns: \n",
        "    The float adapted weight for the feature vector and the treatment type.\n",
        "  \"\"\"\n",
        "  old_weight = weight(dataset, X, T)\n",
        "  pi_0 = pi(dataset, 0)\n",
        "  pi_1 = pi(dataset, 1)\n",
        "  adapted_weight = old_weight / 2 * (T / pi_1 + (1-T) / pi_0)\n",
        "\n",
        "  return adapted_weight"
      ],
      "metadata": {
        "id": "50Sk4ls9AbF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set**"
      ],
      "metadata": {
        "id": "U7emOyPoFfe4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5srSsB01ULi"
      },
      "outputs": [],
      "source": [
        " class dataset(): \n",
        "   \"\"\"\n",
        "   Model selection procedure for causal inference models\n",
        "\n",
        "   Args: \n",
        "    dataset: input file containing the features, treatments and outcomes \n",
        "    (add file type)\n",
        "   \"\"\"\n",
        "   def __init__(self, dataset):\n",
        "     \"\"\"\n",
        "        Takes a dataset as input and returns a parsed Torch tensor where each \n",
        "        row {X_i, T_i, Y_i} represents the feature vector, the treatment type \n",
        "        and the outcome for a particular person.\n",
        "     \"\"\"\n",
        "    #  Add Chang's parsing of the dataset\n",
        "\n",
        "    # Each n row represents a person; the first column is the m dimensional float\n",
        "    # feature vector, the second column is the 0/1 treatment type, and the \n",
        "    # third column is the float outcome.\n",
        "    self.data = torch.Tensor(self.size, 3)\n",
        "\n",
        "    # Number of persons in the dataset\n",
        "    self.size = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed Forward Network**"
      ],
      "metadata": {
        "id": "zTzHImuQFoRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class net(): \n",
        "  \"\"\"\n",
        "  Feed forward neural network that takes the feature vectors as inputs and \n",
        "  estimates the outcome given the treatment type. \n",
        "\n",
        "  Args: \n",
        "\n",
        "  Returns:\n",
        "    \n",
        "  \"\"\"\n",
        "  # Extract the feature vectors from self.dataset for the input of the \n",
        "  # network. Extract the outcomes and treatement type for the weight\n",
        "  # optimisation backward process. \n",
        "\n",
        "  # Add Lucas' forward and backward passes (I am guessing a similar \n",
        "  # structure to the one defined in the net of Assignement A2.3)\n"
      ],
      "metadata": {
        "id": "5kHHShcLk7rX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}